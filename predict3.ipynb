{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from library.model.u_net import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from library.loader.data_loader import DepthDataSet\n",
    "\n",
    "def plot_img_and_mask(img, mask):\n",
    "    classes = mask.shape[2] if len(mask.shape) > 2 else 1\n",
    "    fig, ax = plt.subplots(1, classes + 1)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].imshow(img)\n",
    "    if classes > 1:\n",
    "        for i in range(classes):\n",
    "            ax[i+1].set_title(f'Output mask (class {i+1})')\n",
    "            ax[i+1].imshow(mask[:, :, i])\n",
    "    else:\n",
    "        ax[1].set_title(f'Output mask')\n",
    "        ax[1].imshow(mask)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    #plt.savefig('/content/drive/My Drive/Colab Notebooks/S15AB/data/output/{}'.format(filename))\n",
    "    plt.show()\n",
    "\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "\n",
    "    img = torch.from_numpy(DepthDataSet.preprocess(full_img, scale_factor))\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "\n",
    "        if net.n_classes > 1:\n",
    "            probs = F.softmax(output, dim=1)\n",
    "        else:\n",
    "            probs = torch.sigmoid(output)\n",
    "\n",
    "        probs = probs.squeeze(0)\n",
    "\n",
    "        tf = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(full_img.size[1]),\n",
    "                transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        probs = tf(probs.cpu())\n",
    "        full_mask = probs.squeeze().cpu().numpy()\n",
    "\n",
    "    return full_mask > out_threshold\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Predict masks from input images',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--model', '-m', default='MODEL.pth',\n",
    "                        metavar='FILE',\n",
    "                        help=\"Specify the file in which the model is stored\")\n",
    "    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+',\n",
    "                        help='filenames of input images', required=True)\n",
    "\n",
    "    parser.add_argument('--output', '-o', metavar='INPUT', nargs='+',\n",
    "                        help='Filenames of ouput images')\n",
    "    parser.add_argument('--viz', '-v', action='store_true',\n",
    "                        help=\"Visualize the images as they are processed\",\n",
    "                        default=False)\n",
    "    parser.add_argument('--no-save', '-n', action='store_true',\n",
    "                        help=\"Do not save the output masks\",\n",
    "                        default=False)\n",
    "    parser.add_argument('--mask-threshold', '-t', type=float,\n",
    "                        help=\"Minimum probability value to consider a mask pixel white\",\n",
    "                        default=0.5)\n",
    "    parser.add_argument('--scale', '-s', type=float,\n",
    "                        help=\"Scale factor for the input images\",\n",
    "                        default=0.5)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_output_filenames(args):\n",
    "    in_files = args.input\n",
    "    out_files = []\n",
    "\n",
    "    if not args.output:\n",
    "        for f in in_files:\n",
    "            pathsplit = os.path.splitext(f)\n",
    "            out_files.append(\"{}_OUT{}\".format(pathsplit[0], pathsplit[1]))\n",
    "    elif len(in_files) != len(args.output):\n",
    "        logging.error(\"Input files and output files are not of the same length\")\n",
    "        raise SystemExit()\n",
    "    else:\n",
    "        out_files = args.output\n",
    "\n",
    "    return out_files\n",
    "\n",
    "\n",
    "def mask_to_image(mask):\n",
    "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    in_files = args.input\n",
    "    out_files = get_output_filenames(args)\n",
    "\n",
    "    net = UNet(n_channels=3, n_classes=2)\n",
    "\n",
    "    logging.info(\"Loading model {}\".format(args.model))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Using device {device}')\n",
    "    net.to(device=device)\n",
    "    state_dict = torch.load(args.model, map_location=device)\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        if 'module' not in k:\n",
    "            k = 'module.'+k\n",
    "        else:\n",
    "            k = k.replace('features.module.', 'module.features.')\n",
    "        new_state_dict[k]=v\n",
    "\n",
    "    net.load_state_dict(new_state_dict, strict=False)\n",
    "    #net.load_state_dict(torch.load(args.model, map_location=device))\n",
    "\n",
    "    logging.info(\"Model loaded !\")\n",
    "\n",
    "    for i, fn in enumerate(in_files):\n",
    "        logging.info(\"\\nPredicting image {} ...\".format(fn))\n",
    "\n",
    "        img = Image.open(fn)\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                           full_img=img,\n",
    "                           scale_factor=args.scale,\n",
    "                           out_threshold=args.mask_threshold,\n",
    "                           device=device)\n",
    "\n",
    "        if not args.no_save:\n",
    "            out_fn = out_files[i]\n",
    "            result = mask_to_image(mask)\n",
    "            result.save(out_files[i])\n",
    "\n",
    "            logging.info(\"Mask saved to {}\".format(out_files[i]))\n",
    "\n",
    "        if args.viz:\n",
    "            logging.info(\"Visualizing results for image {}, close to continue ...\".format(fn))\n",
    "            plot_img_and_mask(img, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
